{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# RCNN OBJECT DETECTION DEMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our trained Faster R-CNN on the LISA Traffic Signs dataset (Simply dataset by keep only 3 classes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBdjK2G5ywuc"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "Import the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-IMl4b6BdGO"
   },
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYPCiag2iz_q"
   },
   "source": [
    "Patches:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'lisa/records/classes.pbtxt'\n",
    "categoryIdx = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_FROZEN_GRAPH = os.getcwd()+'/lisa/experiments/exported_model/frozen_inference_graph.pb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVU3U_J6IJVb"
   },
   "source": [
    "For the sake of simplicity we will test on 1 image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = os.getcwd() + '/test_images/test1.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a set of colors for our class labels\n",
    "COLORS = np.random.uniform(0, 255, size=(NUM_CLASSES, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7aOtOlebK7h"
   },
   "source": [
    "Load an object detection model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.Graph()\n",
    "with model.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detection and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a session to perform inference\n",
    "with model.as_default():\n",
    "    with tf.Session(graph=model) as sess:\n",
    "        # grab a reference to the input image tensor and the boxes\n",
    "        # tensor\n",
    "        imageTensor = model.get_tensor_by_name(\"image_tensor:0\")\n",
    "        boxesTensor = model.get_tensor_by_name(\"detection_boxes:0\")\n",
    "\n",
    "        # for each bounding box we would like to know the score\n",
    "        # (i.e., probability) and class label\n",
    "        scoresTensor = model.get_tensor_by_name(\"detection_scores:0\")\n",
    "        classesTensor = model.get_tensor_by_name(\"detection_classes:0\")\n",
    "        numDetections = model.get_tensor_by_name(\"num_detections:0\")\n",
    "        # load the image from disk\n",
    "        image = cv2.imread(TEST_IMAGE_PATH)\n",
    "        (H, W) = image.shape[:2]\n",
    "\n",
    "        # check to see if we should resize along the width\n",
    "        if W > H and W > 1000:\n",
    "            image = imutils.resize(image, width=1000)\n",
    "\n",
    "        # otherwise, check to see if we should resize along the\n",
    "        # height\n",
    "        elif H > W and H > 1000:\n",
    "            image = imutils.resize(image, height=1000)\n",
    "\n",
    "        # prepare the image for detection\n",
    "        (H, W) = image.shape[:2]\n",
    "        output = image.copy()\n",
    "        image = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2RGB)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        # perform inference and compute the bounding boxes,\n",
    "        # probabilities, and class labels\n",
    "        (boxes, scores, labels, N) = sess.run(\n",
    "        [boxesTensor, scoresTensor, classesTensor, numDetections],\n",
    "        feed_dict={imageTensor: image})\n",
    "\n",
    "        # squeeze the lists into a single dimension\n",
    "        boxes = np.squeeze(boxes)\n",
    "        scores = np.squeeze(scores)\n",
    "        labels = np.squeeze(labels)\n",
    "        \n",
    "        # loop over the bounding box predictions\n",
    "        for (box, score, label) in zip(boxes, scores, labels):\n",
    "            # if the predicted probability is less than the minimum\n",
    "            # confidence, ignore it\n",
    "            if score < 0.5: #min_confidence\n",
    "                continue\n",
    "\n",
    "            # scale the bounding box from the range [0, 1] to [W, H]\n",
    "            (startY, startX, endY, endX) = box\n",
    "            startX = int(startX * W)\n",
    "            startY = int(startY * H)\n",
    "            endX = int(endX * W)\n",
    "            endY = int(endY * H)\n",
    "            # draw the prediction on the output image\n",
    "            label = categoryIdx[label]\n",
    "            idx = int(label[\"id\"]) - 1\n",
    "            label = \"{}: {:.2f}\".format(label[\"name\"], score)\n",
    "            cv2.rectangle(output, (startX, startY), (endX, endY),\n",
    "            COLORS[idx], 2)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.putText(output, label, (startX, y),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.3, COLORS[idx], 1)\n",
    "\n",
    "        # show the output image\n",
    "        cv2.imshow(\"Output\", output)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLlmm9JojEKm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "//learning/brain/python/client:colab_notebook",
    "kind": "private"
   },
   "name": "object_detection_tutorial.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1LNYL6Zsn9Xlil2CVNOTsgDZQSBKeOjCh",
     "timestamp": 1566498233247
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566488313397
    },
    {
     "file_id": "/piper/depot/google3/third_party/py/tensorflow_docs/g3doc/en/r2/tutorials/generative/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1566145894046
    },
    {
     "file_id": "1nBPoWynOV0auSIy40eQcBIk9C6YRSkI8",
     "timestamp": 1566145841085
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556295408037
    },
    {
     "file_id": "1layerger-51XwWOwYMY_5zHaCavCeQkO",
     "timestamp": 1556214267924
    },
    {
     "file_id": "/piper/depot/google3/third_party/tensorflow_models/object_detection/object_detection_tutorial.ipynb?workspaceId=markdaoust:copybara_AFABFE845DCD573AD3D43A6BAFBE77D4_0::citc",
     "timestamp": 1556207836484
    },
    {
     "file_id": "1w6mqQiNV3liPIX70NOgitOlDF1_4sRMw",
     "timestamp": 1556154824101
    },
    {
     "file_id": "https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb",
     "timestamp": 1556150293326
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
